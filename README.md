This is the documentation of text autoencoder and MApping function between [image embeddings](https://github.com/anindyasdas/stackGANautoen) and text embeddings obtained from text autoencoder.
# endtoend
End-to-End MMD and GAN model and text autoencoder
Download Flower images : https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz
Rename the jpg folder to images and unzip 102flowers.zip and put it inside 102flowers folder
# CUB dataset :
https://drive.google.com/file/d/1yzcR5J0D9pcI2KlZU0zzxl3Hz_C2QgJK/view?usp=sharing Download the folders take out the images folder
http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz downloand and extract, put images folder inside birds_dataset/CUB_200_2011
- Create two folders glove.6B and glove.6B_flowers and download the glove embeddings and store
- Download and extract 1-billion daataset https://www.statmt.org/lm-benchmark/1-billion-word-language-modeling-benchmark-r13output.tar.gz
